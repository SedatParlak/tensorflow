{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMPra42oDOCmmoaOoDg8ahD"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Transfer Learning Part 1: Feature Extraction\n",
        "\n",
        "Transfer learning is a leveraging a working model's existing architecture and learned paterns for our own problem.\n",
        "\n",
        "There are two main benefits:\n",
        "* Can leverage an existing neural network architecture proven to work on problems similar to our own\n",
        "* Can leverage a working neural network architecture which has already learned patterns on similar data to or own, then we can adapt those patterns to our own data."
      ],
      "metadata": {
        "id": "J6sC-d0FCaSZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Libraries\n",
        "import os\n",
        "import datetime\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ],
      "metadata": {
        "id": "Qe_Q51veQ8bB"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Downloading and becoming one with data\n",
        "\n",
        "In the last notebook, we used Food101 data and work with all the data however this time we will use only 10 percent of the same data and try to see power of transfer learning."
      ],
      "metadata": {
        "id": "5vpWRl0SGDKd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get data (%10 of 10 food classes from Food101)\n",
        "import zipfile\n",
        "\n",
        "# Download the data\n",
        "!wget https://storage.googleapis.com/ztm_tf_course/food_vision/10_food_classes_10_percent.zip\n",
        "\n",
        "# Unzip the downloaded file\n",
        "zip_ref = zipfile.ZipFile('10_food_classes_10_percent.zip')\n",
        "zip_ref.extractall()\n",
        "zip_ref.close()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ENKN6zC8GQL_",
        "outputId": "5a2490fe-f594-4ee9-e161-57fa155491cd"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-06-21 09:20:38--  https://storage.googleapis.com/ztm_tf_course/food_vision/10_food_classes_10_percent.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 173.194.69.128, 173.194.79.128, 108.177.119.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|173.194.69.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 168546183 (161M) [application/zip]\n",
            "Saving to: ‘10_food_classes_10_percent.zip.1’\n",
            "\n",
            "10_food_classes_10_ 100%[===================>] 160.74M  37.7MB/s    in 5.0s    \n",
            "\n",
            "2023-06-21 09:20:43 (31.8 MB/s) - ‘10_food_classes_10_percent.zip.1’ saved [168546183/168546183]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Walk through 10 percent data directory and list number of files\n",
        "for dir in os.walk('10_food_classes_10_percent'):\n",
        "    print(f\"There are {len(dir[1])} directories and {len(dir[2])} images in '{dir[0]}'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GlPd3OzwW3yE",
        "outputId": "0ccfd977-dabd-4d45-b051-87e672fdd4ab"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 2 directories and 0 images in '10_food_classes_10_percent'\n",
            "There are 10 directories and 0 images in '10_food_classes_10_percent/train'\n",
            "There are 0 directories and 75 images in '10_food_classes_10_percent/train/sushi'\n",
            "There are 0 directories and 75 images in '10_food_classes_10_percent/train/chicken_wings'\n",
            "There are 0 directories and 75 images in '10_food_classes_10_percent/train/hamburger'\n",
            "There are 0 directories and 75 images in '10_food_classes_10_percent/train/grilled_salmon'\n",
            "There are 0 directories and 75 images in '10_food_classes_10_percent/train/fried_rice'\n",
            "There are 0 directories and 75 images in '10_food_classes_10_percent/train/pizza'\n",
            "There are 0 directories and 75 images in '10_food_classes_10_percent/train/chicken_curry'\n",
            "There are 0 directories and 75 images in '10_food_classes_10_percent/train/ramen'\n",
            "There are 0 directories and 75 images in '10_food_classes_10_percent/train/steak'\n",
            "There are 0 directories and 75 images in '10_food_classes_10_percent/train/ice_cream'\n",
            "There are 10 directories and 0 images in '10_food_classes_10_percent/test'\n",
            "There are 0 directories and 250 images in '10_food_classes_10_percent/test/sushi'\n",
            "There are 0 directories and 250 images in '10_food_classes_10_percent/test/chicken_wings'\n",
            "There are 0 directories and 250 images in '10_food_classes_10_percent/test/hamburger'\n",
            "There are 0 directories and 250 images in '10_food_classes_10_percent/test/grilled_salmon'\n",
            "There are 0 directories and 250 images in '10_food_classes_10_percent/test/fried_rice'\n",
            "There are 0 directories and 250 images in '10_food_classes_10_percent/test/pizza'\n",
            "There are 0 directories and 250 images in '10_food_classes_10_percent/test/chicken_curry'\n",
            "There are 0 directories and 250 images in '10_food_classes_10_percent/test/ramen'\n",
            "There are 0 directories and 250 images in '10_food_classes_10_percent/test/steak'\n",
            "There are 0 directories and 250 images in '10_food_classes_10_percent/test/ice_cream'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating data loaders (preparing the data)\n",
        "\n",
        "We'll use the `ImageDataGenerator` class to load in our images in batches"
      ],
      "metadata": {
        "id": "QxPxsMrCRavG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the global variables\n",
        "BATCH_SIZE = 32\n",
        "IMAGE_SIZE = (224, 224)\n",
        "\n",
        "# Setup data inputs\n",
        "train_dir = '10_food_classes_10_percent/train/'\n",
        "test_dir = '10_food_classes_10_percent/test/'\n",
        "\n",
        "train_datagen = ImageDataGenerator(rescale=1/255.)\n",
        "test_datagen = ImageDataGenerator(rescale=1/255.)\n",
        "\n",
        "print('Training images:')\n",
        "train_data = train_datagen.flow_from_directory(train_dir,\n",
        "                                               target_size=IMAGE_SIZE,\n",
        "                                               class_mode='categorical',\n",
        "                                               batch_size=BATCH_SIZE)\n",
        "\n",
        "print('\\nTest images:')\n",
        "test_data = test_datagen.flow_from_directory(test_dir,\n",
        "                                             target_size=IMAGE_SIZE,\n",
        "                                             class_mode='categorical',\n",
        "                                             batch_size=BATCH_SIZE)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Y63KQkmZYWR",
        "outputId": "f6639601-ac6b-47fe-ce36-7e10d2333988"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training images:\n",
            "Found 750 images belonging to 10 classes.\n",
            "\n",
            "Test images:\n",
            "Found 2500 images belonging to 10 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setting up callbacks (things to run while our model trains)\n",
        "\n",
        "Callbacks are extra functionality you can add to your models to be perfomeed during or after training. Some of the most populer callbacks:\n",
        "\n",
        "* Tracking experiments with the TensorBoard callback\n",
        "* Model checkpoint with the ModelCheckpoint callback\n",
        "* Stopping a model from training (before it trains too long and overfits) with the EarlyStopping callback"
      ],
      "metadata": {
        "id": "FLXU5FxZcKvq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a TensorBoard callbakc (functionized because we need to create a new one for each model)\n",
        "def create_tensorboard_callback(dir_name, experiment_name):\n",
        "    log_dir = dir_name + '/' + experiment_name + '/' + datetime.datetime.now().strftime('%Y%m%d-%H%M%S')\n",
        "    tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir)\n",
        "    print(f'Saving TensorBoard log files to: {log_dir}')\n",
        "    return tensorboard_callback"
      ],
      "metadata": {
        "id": "cxnTJ500bW9n"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating models using TensorFlow Hub\n",
        "\n",
        "In the past notebooks, we created our model's architecture layer by layer from scratch. Now, we are going to do similar proces but majority of our model's layers will come from TensorFlow Hub. Here you can find out pretrained models: https://tfhub.dev/\n",
        "\n",
        "After browsing in TensorFlow Hub, I found out following feature vector models:\n",
        "\n",
        "* efficientnet: https://tfhub.dev/tensorflow/efficientnet/b0/feature-vector/1\n",
        "* resnet: https://tfhub.dev/google/imagenet/resnet_v2_50/feature_vector/5"
      ],
      "metadata": {
        "id": "xjByLdvNfrjX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's compare the following models\n",
        "resnet_url = 'https://tfhub.dev/google/imagenet/resnet_v2_50/feature_vector/5'\n",
        "efficientnet_url = 'https://tfhub.dev/tensorflow/efficientnet/b0/feature-vector/1'"
      ],
      "metadata": {
        "id": "mCfE32Qhj9dH"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's make a create_model() function to create a model from URL\n",
        "def create_model(model_url, num_classes=10):\n",
        "    '''\n",
        "    Takes a TensorFlow Hub url and create a model sequential\n",
        "\n",
        "    Args:\n",
        "        model_url(str): A Tensorflow Hub url\n",
        "        num_classes(int): A number of output neurons in the output layer. Should be equal to target classes. Default 10\n",
        "\n",
        "    Returns:\n",
        "        An uncomplied Keras Sequential model with model_url\n",
        "    '''\n",
        "\n",
        "\n",
        "    # Download the pretrained model and save it as a Keras layer\n",
        "    feature_extract_layer = hub.KerasLayer(model_url,\n",
        "                                           trainable=False,\n",
        "                                           name='feature_extraction_layer',\n",
        "                                           input_shape=IMAGE_SIZE+(3,)) # freeze the already learned patterns\n",
        "\n",
        "    # Create the model\n",
        "    model = tf.keras.Sequential([\n",
        "        feature_extract_layer,\n",
        "        layers.Dense(num_classes, activation='softmax', name='output_layer')\n",
        "    ])\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "LMoZegYrv_rl"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Creating and testing Resnet TensorFlow Hub feature extraction model\n"
      ],
      "metadata": {
        "id": "NdCKIw_l3wJc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create Resnet model\n",
        "resnet_model = create_model(model_url=resnet_url, num_classes=train_data.num_classes)"
      ],
      "metadata": {
        "id": "fsZzMyhE3_Tl"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Summary of the resnet_model\n",
        "resnet_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rbysYSwv4ji2",
        "outputId": "5ec14997-f7b3-4871-ca93-35a268594707"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " feature_extraction_layer (K  (None, 2048)             23564800  \n",
            " erasLayer)                                                      \n",
            "                                                                 \n",
            " output_layer (Dense)        (None, 10)                20490     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 23,585,290\n",
            "Trainable params: 20,490\n",
            "Non-trainable params: 23,564,800\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are `23,585,290` params but only `20,490` of them trainable. Actually, that summarize the transfer learnin well."
      ],
      "metadata": {
        "id": "cY7clkzc5DF_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model\n",
        "resnet_model.compile(\n",
        "    loss='categorical_crossentropy',\n",
        "    optimizer=tf.keras.optimizers.Adam(),\n",
        "    metrics=['accuracy']\n",
        ")"
      ],
      "metadata": {
        "id": "EaaMYPh04kRA"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit the resnet_model\n",
        "resnet_history = resnet_model.fit(train_data,\n",
        "                                  epochs=5,\n",
        "                                  steps_per_epoch=len(train_data),\n",
        "                                  validation_data=test_data,\n",
        "                                  validation_steps=len(test_data),\n",
        "                                  callbacks=[create_tensorboard_callback(dir_name='tensorflow_hub',\n",
        "                                                                         experiment_name='resnet_v2_50')])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dYGITXD36EI-",
        "outputId": "222edc2a-dd31-4375-8ba6-4c387163df67"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving TensorBoard log files to: tensorflow_hub/resnet_v2_50/20230621-123010\n",
            "Epoch 1/5\n",
            "24/24 [==============================] - 20s 845ms/step - loss: 0.7009 - accuracy: 0.7827 - val_loss: 0.7681 - val_accuracy: 0.7632\n",
            "Epoch 2/5\n",
            "24/24 [==============================] - 18s 789ms/step - loss: 0.5184 - accuracy: 0.8680 - val_loss: 0.7048 - val_accuracy: 0.7760\n",
            "Epoch 3/5\n",
            "24/24 [==============================] - 18s 780ms/step - loss: 0.4094 - accuracy: 0.9080 - val_loss: 0.6814 - val_accuracy: 0.7808\n",
            "Epoch 4/5\n",
            "24/24 [==============================] - 19s 804ms/step - loss: 0.3366 - accuracy: 0.9267 - val_loss: 0.6545 - val_accuracy: 0.7868\n",
            "Epoch 5/5\n",
            "24/24 [==============================] - 18s 785ms/step - loss: 0.2848 - accuracy: 0.9520 - val_loss: 0.6495 - val_accuracy: 0.7892\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This transfer learning feature extractor model performed well. Compared with previous models, we get higher score and quicker training time by the way note that we only use 10 percent of the data."
      ],
      "metadata": {
        "id": "lxx6zKU-91NN"
      }
    }
  ]
}