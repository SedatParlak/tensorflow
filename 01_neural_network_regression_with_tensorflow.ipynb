{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LcyshQVV0tsD"
      },
      "source": [
        "# Introduction to Regression with Neural Network in TensorFlow"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tfmMQ1w72x3J"
      },
      "source": [
        "There are many definition for a regression problem but in our case, we're going to simplfy it: prediction a numerical variable based on combination of other variables. Even shorter, predicting a number..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "8v1QKjt_3xBB",
        "outputId": "4eab7a49-7fdc-401c-bb49-06593696404f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2.12.0\n"
          ]
        }
      ],
      "source": [
        "# import tensorflow\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "\n",
        "# import numpy and matplotlib\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UDLnkL8p4UQ_"
      },
      "source": [
        "## Creating data to view and fit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 454
        },
        "id": "RuQAeUbN4tYO",
        "outputId": "99706c53-7b67-4436-f959-e6707f95ed86"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Create features\n",
        "X = np.array([-7.0, -4.0, -1.0, 2.0, 5.0, 8.0, 11.0, 14.0])\n",
        "\n",
        "# Create labels\n",
        "y = np.array([3.0, 6.0, 9.0, 12.0, 15.0, 18.0, 21.0, 24.0])\n",
        "\n",
        "# Visualize features and labels\n",
        "plt.scatter(X, y)\n",
        "plt.xlabel('X')\n",
        "plt.ylabel('y')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jn3mgVDT5RgW",
        "outputId": "027c3027-2aa8-42f2-bafd-26dfbb908397"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([ True,  True,  True,  True,  True,  True,  True,  True])"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y == X + 10"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J-xaVhtv60EW"
      },
      "source": [
        "## Input and output shapes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "6-3TQvFy7-fn",
        "outputId": "0f41d594-8b87-40cd-d5ac-41e247e09348"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((8,), (8,))"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Let's check the input and output shape (Note that these shapes are not correct one)\n",
        "input_shape = X.shape\n",
        "output_shape = y.shape\n",
        "\n",
        "input_shape, output_shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "6b666i2M-IKA",
        "outputId": "dc7edf9d-ffdf-478f-83ac-77c9b899e00e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((), ())"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Let's check another input and output shape (Note that these shapes are not correct one)\n",
        "input_shape = X[0].shape\n",
        "output_shape = y[0].shape\n",
        "\n",
        "input_shape, output_shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "utrAueJD-gku"
      },
      "source": [
        "As you see above, it seems our inputs and outputs have no shape. Let's turn numpy arrays to tensors for finding correct shape."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "U_UJVgHt-gLA",
        "outputId": "8503fd88-6a0f-467a-d3c1-270704a9a04b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(8,), dtype=float64, numpy=array([-7., -4., -1.,  2.,  5.,  8., 11., 14.])>,\n",
              " <tf.Tensor: shape=(8,), dtype=float64, numpy=array([ 3.,  6.,  9., 12., 15., 18., 21., 24.])>)"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Turn numpy array to tensors\n",
        "X = tf.constant(X)\n",
        "y = tf.constant(y)\n",
        "\n",
        "X, y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "vFqJ795t-ew7",
        "outputId": "d9bff2ad-ea93-4b8c-caaa-7131aa2d7f0e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(TensorShape([]), TensorShape([]))"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Check tensor shapes\n",
        "input_shape = X[0].shape\n",
        "output_shape = y[0].shape\n",
        "\n",
        "input_shape, output_shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2u-0fs24pmpF"
      },
      "source": [
        "## Steps in modelling with Tensorflow\n",
        "\n",
        "1. **Creating a model** - define input and output layer, as well as the hidden layers of deep learning model.\n",
        "2. **Compiling  a model** - define the loss function (in other words, the function which tells our model how wrong it is) and optimizer (tells our model how to improve the patterns its learning) and evaluation metrics (what we can use to interpret the performanse of our model)\n",
        "3. **Fitting a model** - letting the model try to find patterns features and labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "aVaI2_oeDYyn",
        "outputId": "325c0d6a-6723-44dc-81b9-ab0282be2318"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "1/1 [==============================] - 5s 5s/step - loss: 8.0771 - mae: 8.0771\n",
            "Epoch 2/5\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 7.9446 - mae: 7.9446\n",
            "Epoch 3/5\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 7.8121 - mae: 7.8121\n",
            "Epoch 4/5\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 7.6796 - mae: 7.6796\n",
            "Epoch 5/5\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 7.5471 - mae: 7.5471\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f8b637994c0>"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# set random seed\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# 1. Create a model using Sequential API\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "# 2. Compiling a model\n",
        "model.compile(\n",
        "    loss=tf.keras.losses.mae, # mae short for mean absolute error\n",
        "    optimizer=tf.keras.optimizers.SGD(), # SGD short for stochastic gradient descent\n",
        "    metrics=['mae']\n",
        ")\n",
        "\n",
        "# 3. Fit the model\n",
        "model.fit(tf.expand_dims(X, axis=-1), y, epochs=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "eoQxKdpKhTgO",
        "outputId": "3d0a3dd9-62f3-4f19-fef8-c5c08ea26a07"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(8,), dtype=float64, numpy=array([-7., -4., -1.,  2.,  5.,  8., 11., 14.])>,\n",
              " <tf.Tensor: shape=(8,), dtype=float64, numpy=array([ 3.,  6.,  9., 12., 15., 18., 21., 24.])>)"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Check X and y\n",
        "X, y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "AKi0_0R8ncy0",
        "outputId": "9806ae23-d40b-4430-ba2d-a7fb8699df59"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 122ms/step\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "array([[29.364626]], dtype=float32)"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Try to make a prediction using our model\n",
        "model.predict([17.0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1zZP0IgNoJxW"
      },
      "source": [
        "Our expection for 17.0 is 20.68 but model prediction is -23.68. This is so bad prediction."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kTyxRAcVniMV"
      },
      "source": [
        "## Improving Model\n",
        "\n",
        "We can improve our model, by altering the steps we took to create a model.\n",
        "\n",
        "1. **Creating a model** - Here we might add more layers, increase the number of hidden units (called neuron) within each of the hidden layers, change the activation function of each layer\n",
        "2. **Compiling a model** - Here we might change the optimization function or perhaps the learning rate of the optimization function\n",
        "3. **Fitting a model** - Here we might change the number of epoch (leave it training for longer) or more data (give the model more example to learn from)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k4u4Bo4WxJj3"
      },
      "source": [
        "### Increasing number of epoch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bi_JOvMdwMLj",
        "outputId": "dda3f867-b5c9-42ca-8454-88c15a37bec0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "1/1 [==============================] - 1s 548ms/step - loss: 19.8287 - mae: 19.8287\n",
            "Epoch 2/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 19.5474 - mae: 19.5474\n",
            "Epoch 3/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 19.2662 - mae: 19.2662\n",
            "Epoch 4/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 18.9849 - mae: 18.9849\n",
            "Epoch 5/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 18.7037 - mae: 18.7037\n",
            "Epoch 6/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 18.4224 - mae: 18.4224\n",
            "Epoch 7/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 18.1412 - mae: 18.1412\n",
            "Epoch 8/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 17.8599 - mae: 17.8599\n",
            "Epoch 9/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 17.5787 - mae: 17.5787\n",
            "Epoch 10/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 17.2974 - mae: 17.2974\n",
            "Epoch 11/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 17.0162 - mae: 17.0162\n",
            "Epoch 12/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 16.7349 - mae: 16.7349\n",
            "Epoch 13/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 16.4537 - mae: 16.4537\n",
            "Epoch 14/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 16.1724 - mae: 16.1724\n",
            "Epoch 15/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 15.8912 - mae: 15.8912\n",
            "Epoch 16/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 15.6099 - mae: 15.6099\n",
            "Epoch 17/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 15.3287 - mae: 15.3287\n",
            "Epoch 18/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 15.0474 - mae: 15.0474\n",
            "Epoch 19/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 14.7766 - mae: 14.7766\n",
            "Epoch 20/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 14.6441 - mae: 14.6441\n",
            "Epoch 21/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 14.5116 - mae: 14.5116\n",
            "Epoch 22/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 14.3791 - mae: 14.3791\n",
            "Epoch 23/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 14.2466 - mae: 14.2466\n",
            "Epoch 24/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 14.1141 - mae: 14.1141\n",
            "Epoch 25/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 13.9816 - mae: 13.9816\n",
            "Epoch 26/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 13.8491 - mae: 13.8491\n",
            "Epoch 27/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 13.7166 - mae: 13.7166\n",
            "Epoch 28/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 13.5841 - mae: 13.5841\n",
            "Epoch 29/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 13.4516 - mae: 13.4516\n",
            "Epoch 30/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 13.3191 - mae: 13.3191\n",
            "Epoch 31/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 13.1866 - mae: 13.1866\n",
            "Epoch 32/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 13.0541 - mae: 13.0541\n",
            "Epoch 33/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 12.9216 - mae: 12.9216\n",
            "Epoch 34/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 12.7891 - mae: 12.7891\n",
            "Epoch 35/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 12.6566 - mae: 12.6566\n",
            "Epoch 36/100\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 12.5241 - mae: 12.5241\n",
            "Epoch 37/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 12.3916 - mae: 12.3916\n",
            "Epoch 38/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 12.2591 - mae: 12.2591\n",
            "Epoch 39/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 12.1266 - mae: 12.1266\n",
            "Epoch 40/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 11.9941 - mae: 11.9941\n",
            "Epoch 41/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 11.8616 - mae: 11.8616\n",
            "Epoch 42/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 11.7291 - mae: 11.7291\n",
            "Epoch 43/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 11.5966 - mae: 11.5966\n",
            "Epoch 44/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 11.4641 - mae: 11.4641\n",
            "Epoch 45/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 11.3316 - mae: 11.3316\n",
            "Epoch 46/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 11.1991 - mae: 11.1991\n",
            "Epoch 47/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 11.0666 - mae: 11.0666\n",
            "Epoch 48/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 10.9341 - mae: 10.9341\n",
            "Epoch 49/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 10.8016 - mae: 10.8016\n",
            "Epoch 50/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 10.6691 - mae: 10.6691\n",
            "Epoch 51/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 10.5366 - mae: 10.5366\n",
            "Epoch 52/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 10.4041 - mae: 10.4041\n",
            "Epoch 53/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 10.2716 - mae: 10.2716\n",
            "Epoch 54/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 10.1391 - mae: 10.1391\n",
            "Epoch 55/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 10.0066 - mae: 10.0066\n",
            "Epoch 56/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 9.8741 - mae: 9.8741\n",
            "Epoch 57/100\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 9.7416 - mae: 9.7416\n",
            "Epoch 58/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 9.6091 - mae: 9.6091\n",
            "Epoch 59/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 9.4766 - mae: 9.4766\n",
            "Epoch 60/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 9.3441 - mae: 9.3441\n",
            "Epoch 61/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 9.2116 - mae: 9.2116\n",
            "Epoch 62/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 9.0791 - mae: 9.0791\n",
            "Epoch 63/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 8.9466 - mae: 8.9466\n",
            "Epoch 64/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 8.8141 - mae: 8.8141\n",
            "Epoch 65/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 8.6816 - mae: 8.6816\n",
            "Epoch 66/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 8.5491 - mae: 8.5491\n",
            "Epoch 67/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 8.4166 - mae: 8.4166\n",
            "Epoch 68/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 8.2841 - mae: 8.2841\n",
            "Epoch 69/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 8.1516 - mae: 8.1516\n",
            "Epoch 70/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 8.0191 - mae: 8.0191\n",
            "Epoch 71/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 7.8866 - mae: 7.8866\n",
            "Epoch 72/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 7.7541 - mae: 7.7541\n",
            "Epoch 73/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 7.6216 - mae: 7.6216\n",
            "Epoch 74/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 7.4891 - mae: 7.4891\n",
            "Epoch 75/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 7.3566 - mae: 7.3566\n",
            "Epoch 76/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 7.2241 - mae: 7.2241\n",
            "Epoch 77/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 7.0916 - mae: 7.0916\n",
            "Epoch 78/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 6.9591 - mae: 6.9591\n",
            "Epoch 79/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 6.9488 - mae: 6.9488\n",
            "Epoch 80/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 6.9431 - mae: 6.9431\n",
            "Epoch 81/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 6.9375 - mae: 6.9375\n",
            "Epoch 82/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 6.9319 - mae: 6.9319\n",
            "Epoch 83/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 6.9263 - mae: 6.9263\n",
            "Epoch 84/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 6.9206 - mae: 6.9206\n",
            "Epoch 85/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 6.9150 - mae: 6.9150\n",
            "Epoch 86/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 6.9094 - mae: 6.9094\n",
            "Epoch 87/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 6.9038 - mae: 6.9038\n",
            "Epoch 88/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 6.8981 - mae: 6.8981\n",
            "Epoch 89/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 6.8925 - mae: 6.8925\n",
            "Epoch 90/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 6.8869 - mae: 6.8869\n",
            "Epoch 91/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 6.8813 - mae: 6.8813\n",
            "Epoch 92/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 6.8756 - mae: 6.8756\n",
            "Epoch 93/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 6.8700 - mae: 6.8700\n",
            "Epoch 94/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 6.8644 - mae: 6.8644\n",
            "Epoch 95/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 6.8587 - mae: 6.8587\n",
            "Epoch 96/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 6.8531 - mae: 6.8531\n",
            "Epoch 97/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 6.8475 - mae: 6.8475\n",
            "Epoch 98/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 6.8419 - mae: 6.8419\n",
            "Epoch 99/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 6.8363 - mae: 6.8363\n",
            "Epoch 100/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 6.8306 - mae: 6.8306\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f8b637032b0>"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Let's rebuild model (increasing number of epoch)\n",
        "\n",
        "# 1. Create a model using Sequential API\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "# 2. Compiling a model\n",
        "model.compile(\n",
        "    loss=tf.keras.losses.mae, # mae short for mean absolute error\n",
        "    optimizer=tf.keras.optimizers.SGD(), # SGD short for stochastic gradient descent\n",
        "    metrics=['mae']\n",
        ")\n",
        "\n",
        "# 3. Fit the model\n",
        "model.fit(tf.expand_dims(X, axis=-1), y, epochs=100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "h8O7Wj--wZjS",
        "outputId": "6328c206-027e-4c87-dedc-75bb5f28032b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(8,), dtype=float64, numpy=array([-7., -4., -1.,  2.,  5.,  8., 11., 14.])>,\n",
              " <tf.Tensor: shape=(8,), dtype=float64, numpy=array([ 3.,  6.,  9., 12., 15., 18., 21., 24.])>)"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Remind X and y\n",
        "X, y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "XYtsooJdwMG8",
        "outputId": "e4531033-f7f4-4315-fd99-0c1f45493b8f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 91ms/step\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "array([[29.743635]], dtype=float32)"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Let's make a new prediction\n",
        "model.predict([17.0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0QOofSnrwnDT"
      },
      "source": [
        "Our expection is 27 and model prediction is 26.60. This is better and close than before."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jE4gt4ePxQy7"
      },
      "source": [
        "### Adding more hidden layers with 100 neuron"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "XHz90iinobiX",
        "outputId": "f70f47c0-1c40-4d3d-fa28-78694da48c06"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "1/1 [==============================] - 1s 1s/step - loss: 13.8049 - mae: 13.8049\n",
            "Epoch 2/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 13.4241 - mae: 13.4241\n",
            "Epoch 3/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 13.0571 - mae: 13.0571\n",
            "Epoch 4/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 12.7196 - mae: 12.7196\n",
            "Epoch 5/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 12.3550 - mae: 12.3550\n",
            "Epoch 6/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 11.9356 - mae: 11.9356\n",
            "Epoch 7/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 11.4671 - mae: 11.4671\n",
            "Epoch 8/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 10.9353 - mae: 10.9353\n",
            "Epoch 9/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 10.2892 - mae: 10.2892\n",
            "Epoch 10/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 9.4856 - mae: 9.4856\n",
            "Epoch 11/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 8.4477 - mae: 8.4477\n",
            "Epoch 12/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 7.0790 - mae: 7.0790\n",
            "Epoch 13/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 5.2732 - mae: 5.2732\n",
            "Epoch 14/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 3.9208 - mae: 3.9208\n",
            "Epoch 15/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 3.9993 - mae: 3.9993\n",
            "Epoch 16/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 3.9291 - mae: 3.9291\n",
            "Epoch 17/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 3.9518 - mae: 3.9518\n",
            "Epoch 18/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 3.9381 - mae: 3.9381\n",
            "Epoch 19/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 3.9033 - mae: 3.9033\n",
            "Epoch 20/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 3.9491 - mae: 3.9491\n",
            "Epoch 21/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 3.8500 - mae: 3.8500\n",
            "Epoch 22/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 3.9625 - mae: 3.9625\n",
            "Epoch 23/100\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 3.7957 - mae: 3.7957\n",
            "Epoch 24/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 3.9766 - mae: 3.9766\n",
            "Epoch 25/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 3.7708 - mae: 3.7708\n",
            "Epoch 26/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 3.9755 - mae: 3.9755\n",
            "Epoch 27/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 3.8252 - mae: 3.8252\n",
            "Epoch 28/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 3.8713 - mae: 3.8713\n",
            "Epoch 29/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 3.8408 - mae: 3.8408\n",
            "Epoch 30/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 3.8135 - mae: 3.8135\n",
            "Epoch 31/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 3.8578 - mae: 3.8578\n",
            "Epoch 32/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 3.7545 - mae: 3.7545\n",
            "Epoch 33/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 3.8756 - mae: 3.8756\n",
            "Epoch 34/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 3.6929 - mae: 3.6929\n",
            "Epoch 35/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 3.8945 - mae: 3.8945\n",
            "Epoch 36/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 3.6978 - mae: 3.6978\n",
            "Epoch 37/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 3.8145 - mae: 3.8145\n",
            "Epoch 38/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 3.7539 - mae: 3.7539\n",
            "Epoch 39/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 3.7512 - mae: 3.7512\n",
            "Epoch 40/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 3.7737 - mae: 3.7737\n",
            "Epoch 41/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 3.6847 - mae: 3.6847\n",
            "Epoch 42/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 3.7991 - mae: 3.7991\n",
            "Epoch 43/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 3.6171 - mae: 3.6171\n",
            "Epoch 44/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 3.8221 - mae: 3.8221\n",
            "Epoch 45/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 3.6238 - mae: 3.6238\n",
            "Epoch 46/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 3.7889 - mae: 3.7889\n",
            "Epoch 47/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 3.6838 - mae: 3.6838\n",
            "Epoch 48/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 3.6674 - mae: 3.6674\n",
            "Epoch 49/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 3.7101 - mae: 3.7101\n",
            "Epoch 50/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 3.5970 - mae: 3.5970\n",
            "Epoch 51/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 3.7350 - mae: 3.7350\n",
            "Epoch 52/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 3.5439 - mae: 3.5439\n",
            "Epoch 53/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 3.7327 - mae: 3.7327\n",
            "Epoch 54/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 3.6065 - mae: 3.6065\n",
            "Epoch 55/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 3.6365 - mae: 3.6365\n",
            "Epoch 56/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 3.6311 - mae: 3.6311\n",
            "Epoch 57/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 3.5605 - mae: 3.5605\n",
            "Epoch 58/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 3.6606 - mae: 3.6606\n",
            "Epoch 59/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 3.4838 - mae: 3.4838\n",
            "Epoch 60/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 3.6902 - mae: 3.6902\n",
            "Epoch 61/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 3.4999 - mae: 3.4999\n",
            "Epoch 62/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 3.6113 - mae: 3.6113\n",
            "Epoch 63/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 3.5276 - mae: 3.5276\n",
            "Epoch 64/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 3.5333 - mae: 3.5333\n",
            "Epoch 65/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 3.5571 - mae: 3.5571\n",
            "Epoch 66/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 3.4641 - mae: 3.4641\n",
            "Epoch 67/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 3.6273 - mae: 3.6273\n",
            "Epoch 68/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 3.4426 - mae: 3.4426\n",
            "Epoch 69/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 3.5473 - mae: 3.5473\n",
            "Epoch 70/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 3.4747 - mae: 3.4747\n",
            "Epoch 71/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 3.4638 - mae: 3.4638\n",
            "Epoch 72/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 3.5060 - mae: 3.5060\n",
            "Epoch 73/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 3.3775 - mae: 3.3775\n",
            "Epoch 74/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 3.5392 - mae: 3.5392\n",
            "Epoch 75/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 3.3583 - mae: 3.3583\n",
            "Epoch 76/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 3.5108 - mae: 3.5108\n",
            "Epoch 77/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 3.4280 - mae: 3.4280\n",
            "Epoch 78/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 3.3793 - mae: 3.3793\n",
            "Epoch 79/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 3.4608 - mae: 3.4608\n",
            "Epoch 80/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 3.2862 - mae: 3.2862\n",
            "Epoch 81/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 3.4952 - mae: 3.4952\n",
            "Epoch 82/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 3.3149 - mae: 3.3149\n",
            "Epoch 83/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 3.3942 - mae: 3.3942\n",
            "Epoch 84/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 3.3491 - mae: 3.3491\n",
            "Epoch 85/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 3.2973 - mae: 3.2973\n",
            "Epoch 86/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 3.3844 - mae: 3.3844\n",
            "Epoch 87/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 3.2274 - mae: 3.2274\n",
            "Epoch 88/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 3.3751 - mae: 3.3751\n",
            "Epoch 89/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 3.2853 - mae: 3.2853\n",
            "Epoch 90/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 3.2776 - mae: 3.2776\n",
            "Epoch 91/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 3.3197 - mae: 3.3197\n",
            "Epoch 92/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 3.1725 - mae: 3.1725\n",
            "Epoch 93/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 3.3600 - mae: 3.3600\n",
            "Epoch 94/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 3.1869 - mae: 3.1869\n",
            "Epoch 95/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 3.2666 - mae: 3.2666\n",
            "Epoch 96/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 3.2614 - mae: 3.2614\n",
            "Epoch 97/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 3.1442 - mae: 3.1442\n",
            "Epoch 98/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 3.2977 - mae: 3.2977\n",
            "Epoch 99/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 3.1311 - mae: 3.1311\n",
            "Epoch 100/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 3.2286 - mae: 3.2286\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f8b6189bf40>"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Let's rebuild model\n",
        "\n",
        "# 1. Create a model \n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(100, activation='relu'),\n",
        "    tf.keras.layers.Dense(100, activation='relu'),\n",
        "    tf.keras.layers.Dense(100, activation='relu'),\n",
        "    tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "# 2. Compiling model\n",
        "model.compile(\n",
        "    loss=tf.keras.losses.mae,\n",
        "    optimizer=tf.keras.optimizers.SGD(),\n",
        "    metrics=['mae']\n",
        ")\n",
        "\n",
        "# 3. Fit the model\n",
        "model.fit(tf.expand_dims(X, axis=-1), y, epochs=100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "vImeya344s2T",
        "outputId": "265e5e66-35c9-4a32-af9f-05d38c8e9d1e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(8,), dtype=float64, numpy=array([-7., -4., -1.,  2.,  5.,  8., 11., 14.])>,\n",
              " <tf.Tensor: shape=(8,), dtype=float64, numpy=array([ 3.,  6.,  9., 12., 15., 18., 21., 24.])>)"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Let's remind our data\n",
        "X, y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z4maNOdd4szb",
        "outputId": "0810229c-704e-412d-e617-d8cb4ad3eac6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 117ms/step\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "array([[32.572174]], dtype=float32)"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Making a prediction\n",
        "model.predict([17.0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MaQzIYwi4swu"
      },
      "source": [
        "This prediction is worse than before. The model may have been overfitting."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Twzbb1q4suE"
      },
      "source": [
        "### Change the optimization function\n",
        "\n",
        "Our optimization function is Stochastic Gradient Descent, let's make it Adam and see what will happen."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "u1bw5qU44sre",
        "outputId": "4c920a4b-a3e4-4fa5-b3bd-8369d6eec3aa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "1/1 [==============================] - 2s 2s/step - loss: 14.0337 - mae: 14.0337\n",
            "Epoch 2/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 13.6656 - mae: 13.6656\n",
            "Epoch 3/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 13.3149 - mae: 13.3149\n",
            "Epoch 4/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 12.9742 - mae: 12.9742\n",
            "Epoch 5/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 12.6576 - mae: 12.6576\n",
            "Epoch 6/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 12.3634 - mae: 12.3634\n",
            "Epoch 7/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 12.0719 - mae: 12.0719\n",
            "Epoch 8/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 11.7828 - mae: 11.7828\n",
            "Epoch 9/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 11.4840 - mae: 11.4840\n",
            "Epoch 10/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 11.2189 - mae: 11.2189\n",
            "Epoch 11/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 10.9891 - mae: 10.9891\n",
            "Epoch 12/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 10.7488 - mae: 10.7488\n",
            "Epoch 13/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 10.4935 - mae: 10.4935\n",
            "Epoch 14/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 10.2177 - mae: 10.2177\n",
            "Epoch 15/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 9.9252 - mae: 9.9252\n",
            "Epoch 16/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 9.6148 - mae: 9.6148\n",
            "Epoch 17/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 9.2817 - mae: 9.2817\n",
            "Epoch 18/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 8.9208 - mae: 8.9208\n",
            "Epoch 19/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 8.5370 - mae: 8.5370\n",
            "Epoch 20/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 8.1357 - mae: 8.1357\n",
            "Epoch 21/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 7.7052 - mae: 7.7052\n",
            "Epoch 22/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 7.2470 - mae: 7.2470\n",
            "Epoch 23/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 6.7606 - mae: 6.7606\n",
            "Epoch 24/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 6.2463 - mae: 6.2463\n",
            "Epoch 25/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 5.6972 - mae: 5.6972\n",
            "Epoch 26/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 5.1159 - mae: 5.1159\n",
            "Epoch 27/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 4.5069 - mae: 4.5069\n",
            "Epoch 28/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 4.0826 - mae: 4.0826\n",
            "Epoch 29/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 3.8953 - mae: 3.8953\n",
            "Epoch 30/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 4.0242 - mae: 4.0242\n",
            "Epoch 31/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 4.1361 - mae: 4.1361\n",
            "Epoch 32/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 4.2309 - mae: 4.2309\n",
            "Epoch 33/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 4.4517 - mae: 4.4517\n",
            "Epoch 34/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 4.5945 - mae: 4.5945\n",
            "Epoch 35/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 4.6581 - mae: 4.6581\n",
            "Epoch 36/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 4.6516 - mae: 4.6516\n",
            "Epoch 37/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 4.5852 - mae: 4.5852\n",
            "Epoch 38/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 4.4678 - mae: 4.4678\n",
            "Epoch 39/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 4.3084 - mae: 4.3084\n",
            "Epoch 40/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 4.1337 - mae: 4.1337\n",
            "Epoch 41/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 4.0577 - mae: 4.0577\n",
            "Epoch 42/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 3.9809 - mae: 3.9809\n",
            "Epoch 43/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 3.9042 - mae: 3.9042\n",
            "Epoch 44/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 3.8284 - mae: 3.8284\n",
            "Epoch 45/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 3.7556 - mae: 3.7556\n",
            "Epoch 46/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 3.7522 - mae: 3.7522\n",
            "Epoch 47/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 3.8043 - mae: 3.8043\n",
            "Epoch 48/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 3.8412 - mae: 3.8412\n",
            "Epoch 49/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 3.8628 - mae: 3.8628\n",
            "Epoch 50/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 3.8708 - mae: 3.8708\n",
            "Epoch 51/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 3.8659 - mae: 3.8659\n",
            "Epoch 52/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 3.8495 - mae: 3.8495\n",
            "Epoch 53/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 3.8222 - mae: 3.8222\n",
            "Epoch 54/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 3.7845 - mae: 3.7845\n",
            "Epoch 55/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 3.7371 - mae: 3.7371\n",
            "Epoch 56/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 3.6865 - mae: 3.6865\n",
            "Epoch 57/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 3.6188 - mae: 3.6188\n",
            "Epoch 58/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 3.6527 - mae: 3.6527\n",
            "Epoch 59/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 3.6797 - mae: 3.6797\n",
            "Epoch 60/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 3.6958 - mae: 3.6958\n",
            "Epoch 61/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 3.7017 - mae: 3.7017\n",
            "Epoch 62/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 3.6981 - mae: 3.6981\n",
            "Epoch 63/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 3.6867 - mae: 3.6867\n",
            "Epoch 64/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 3.6672 - mae: 3.6672\n",
            "Epoch 65/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 3.6407 - mae: 3.6407\n",
            "Epoch 66/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 3.6188 - mae: 3.6188\n",
            "Epoch 67/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 3.5786 - mae: 3.5786\n",
            "Epoch 68/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 3.5410 - mae: 3.5410\n",
            "Epoch 69/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 3.5003 - mae: 3.5003\n",
            "Epoch 70/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 3.5282 - mae: 3.5282\n",
            "Epoch 71/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 3.5467 - mae: 3.5467\n",
            "Epoch 72/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 3.5447 - mae: 3.5447\n",
            "Epoch 73/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 3.5273 - mae: 3.5273\n",
            "Epoch 74/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 3.4943 - mae: 3.4943\n",
            "Epoch 75/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 3.4598 - mae: 3.4598\n",
            "Epoch 76/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 3.4210 - mae: 3.4210\n",
            "Epoch 77/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 3.4318 - mae: 3.4318\n",
            "Epoch 78/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 3.4326 - mae: 3.4326\n",
            "Epoch 79/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 3.4246 - mae: 3.4246\n",
            "Epoch 80/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 3.4076 - mae: 3.4076\n",
            "Epoch 81/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.3837 - mae: 3.3837\n",
            "Epoch 82/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 3.3529 - mae: 3.3529\n",
            "Epoch 83/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 3.3306 - mae: 3.3306\n",
            "Epoch 84/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 3.3257 - mae: 3.3257\n",
            "Epoch 85/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 3.3079 - mae: 3.3079\n",
            "Epoch 86/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 3.2761 - mae: 3.2761\n",
            "Epoch 87/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 3.2670 - mae: 3.2670\n",
            "Epoch 88/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 3.2501 - mae: 3.2501\n",
            "Epoch 89/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 3.2283 - mae: 3.2283\n",
            "Epoch 90/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 3.2049 - mae: 3.2049\n",
            "Epoch 91/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 3.1809 - mae: 3.1809\n",
            "Epoch 92/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 3.1706 - mae: 3.1706\n",
            "Epoch 93/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 3.1507 - mae: 3.1507\n",
            "Epoch 94/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 3.1212 - mae: 3.1212\n",
            "Epoch 95/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 3.0867 - mae: 3.0867\n",
            "Epoch 96/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 3.0935 - mae: 3.0935\n",
            "Epoch 97/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 3.0580 - mae: 3.0580\n",
            "Epoch 98/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 3.0200 - mae: 3.0200\n",
            "Epoch 99/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 3.0192 - mae: 3.0192\n",
            "Epoch 100/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 3.0095 - mae: 3.0095\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f8b60474df0>"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Let's rebuild model\n",
        "\n",
        "# 1. Create a model \n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(100, activation='relu'),\n",
        "    tf.keras.layers.Dense(100, activation='relu'),\n",
        "    tf.keras.layers.Dense(100, activation='relu'),\n",
        "    tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "# 2. Compiling model\n",
        "model.compile(\n",
        "    loss=tf.keras.losses.mae,\n",
        "    optimizer=tf.keras.optimizers.Adam(),\n",
        "    metrics=['mae']\n",
        ")\n",
        "\n",
        "# 3. Fit the model\n",
        "model.fit(tf.expand_dims(X, axis=-1), y, epochs=100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "g5WKa2WK6F1s",
        "outputId": "7249a267-f22f-4428-a929-f3219803ac1f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(8,), dtype=float64, numpy=array([-7., -4., -1.,  2.,  5.,  8., 11., 14.])>,\n",
              " <tf.Tensor: shape=(8,), dtype=float64, numpy=array([ 3.,  6.,  9., 12., 15., 18., 21., 24.])>)"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Remind data\n",
        "X, y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "SORLDr9U4so-",
        "outputId": "3a4ac25a-59ca-4403-81a5-fab17002f41e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 81ms/step\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "array([[31.799389]], dtype=float32)"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Making a prediction\n",
        "model.predict([17.0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ygdIVYde6SZm"
      },
      "source": [
        "### Change the learning rate\n",
        "\n",
        "Learning rate's default parameter is 0.001 for Adam optimizer. Let's make it 0.01"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "sVTn5bRf6SRn",
        "outputId": "7f9b1e32-e794-4ef9-96f7-e17bcc1892a4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "1/1 [==============================] - 1s 1s/step - loss: 13.1254 - mae: 13.1254\n",
            "Epoch 2/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 10.8695 - mae: 10.8695\n",
            "Epoch 3/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 8.1470 - mae: 8.1470\n",
            "Epoch 4/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 4.1712 - mae: 4.1712\n",
            "Epoch 5/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 7.1831 - mae: 7.1831\n",
            "Epoch 6/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 6.6215 - mae: 6.6215\n",
            "Epoch 7/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 4.8670 - mae: 4.8670\n",
            "Epoch 8/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 3.8507 - mae: 3.8507\n",
            "Epoch 9/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 4.8601 - mae: 4.8601\n",
            "Epoch 10/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 5.1175 - mae: 5.1175\n",
            "Epoch 11/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 4.5121 - mae: 4.5121\n",
            "Epoch 12/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 3.6956 - mae: 3.6956\n",
            "Epoch 13/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 3.9702 - mae: 3.9702\n",
            "Epoch 14/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 4.4123 - mae: 4.4123\n",
            "Epoch 15/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 4.2788 - mae: 4.2788\n",
            "Epoch 16/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 3.7330 - mae: 3.7330\n",
            "Epoch 17/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 3.4992 - mae: 3.4992\n",
            "Epoch 18/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 3.4056 - mae: 3.4056\n",
            "Epoch 19/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 3.4347 - mae: 3.4347\n",
            "Epoch 20/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 3.3051 - mae: 3.3051\n",
            "Epoch 21/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 3.0154 - mae: 3.0154\n",
            "Epoch 22/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 3.0280 - mae: 3.0280\n",
            "Epoch 23/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 3.2027 - mae: 3.2027\n",
            "Epoch 24/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 2.7172 - mae: 2.7172\n",
            "Epoch 25/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 2.4077 - mae: 2.4077\n",
            "Epoch 26/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 2.3935 - mae: 2.3935\n",
            "Epoch 27/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 2.0192 - mae: 2.0192\n",
            "Epoch 28/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 2.0172 - mae: 2.0172\n",
            "Epoch 29/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 1.6020 - mae: 1.6020\n",
            "Epoch 30/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.2954 - mae: 1.2954\n",
            "Epoch 31/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 1.3111 - mae: 1.3111\n",
            "Epoch 32/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.7806 - mae: 0.7806\n",
            "Epoch 33/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.1278 - mae: 1.1278\n",
            "Epoch 34/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.0110 - mae: 1.0110\n",
            "Epoch 35/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.8654 - mae: 0.8654\n",
            "Epoch 36/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 1.4875 - mae: 1.4875\n",
            "Epoch 37/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.0082 - mae: 1.0082\n",
            "Epoch 38/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 1.0089 - mae: 1.0089\n",
            "Epoch 39/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 1.1923 - mae: 1.1923\n",
            "Epoch 40/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.3535 - mae: 0.3535\n",
            "Epoch 41/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.6668 - mae: 1.6668\n",
            "Epoch 42/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 1.6902 - mae: 1.6902\n",
            "Epoch 43/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.8179 - mae: 0.8179\n",
            "Epoch 44/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 1.3169 - mae: 1.3169\n",
            "Epoch 45/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.4373 - mae: 1.4373\n",
            "Epoch 46/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6770 - mae: 0.6770\n",
            "Epoch 47/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.4721 - mae: 1.4721\n",
            "Epoch 48/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 1.7549 - mae: 1.7549\n",
            "Epoch 49/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.8524 - mae: 0.8524\n",
            "Epoch 50/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.9619 - mae: 0.9619\n",
            "Epoch 51/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.2414 - mae: 1.2414\n",
            "Epoch 52/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.5088 - mae: 0.5088\n",
            "Epoch 53/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 1.1865 - mae: 1.1865\n",
            "Epoch 54/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 1.5701 - mae: 1.5701\n",
            "Epoch 55/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.7493 - mae: 0.7493\n",
            "Epoch 56/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.9519 - mae: 0.9519\n",
            "Epoch 57/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.5703 - mae: 1.5703\n",
            "Epoch 58/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 1.3146 - mae: 1.3146\n",
            "Epoch 59/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.4349 - mae: 0.4349\n",
            "Epoch 60/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.8906 - mae: 0.8906\n",
            "Epoch 61/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.9831 - mae: 0.9831\n",
            "Epoch 62/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.2892 - mae: 0.2892\n",
            "Epoch 63/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6365 - mae: 0.6365\n",
            "Epoch 64/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.4275 - mae: 0.4275\n",
            "Epoch 65/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.8078 - mae: 0.8078\n",
            "Epoch 66/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.9055 - mae: 0.9055\n",
            "Epoch 67/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.1892 - mae: 0.1892\n",
            "Epoch 68/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.8044 - mae: 0.8044\n",
            "Epoch 69/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.8890 - mae: 0.8890\n",
            "Epoch 70/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.3122 - mae: 0.3122\n",
            "Epoch 71/100\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.9923 - mae: 0.9923\n",
            "Epoch 72/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 1.2214 - mae: 1.2214\n",
            "Epoch 73/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.6167 - mae: 0.6167\n",
            "Epoch 74/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 1.1001 - mae: 1.1001\n",
            "Epoch 75/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 1.4409 - mae: 1.4409\n",
            "Epoch 76/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 1.1017 - mae: 1.1017\n",
            "Epoch 77/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.3216 - mae: 0.3216\n",
            "Epoch 78/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 1.0677 - mae: 1.0677\n",
            "Epoch 79/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 1.0142 - mae: 1.0142\n",
            "Epoch 80/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.2683 - mae: 0.2683\n",
            "Epoch 81/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.9055 - mae: 0.9055\n",
            "Epoch 82/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.9050 - mae: 0.9050\n",
            "Epoch 83/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.2591 - mae: 0.2591\n",
            "Epoch 84/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.9281 - mae: 0.9281\n",
            "Epoch 85/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 1.0010 - mae: 1.0010\n",
            "Epoch 86/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.3213 - mae: 0.3213\n",
            "Epoch 87/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 1.1862 - mae: 1.1862\n",
            "Epoch 88/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 1.7458 - mae: 1.7458\n",
            "Epoch 89/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 1.6245 - mae: 1.6245\n",
            "Epoch 90/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.8824 - mae: 0.8824\n",
            "Epoch 91/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.4999 - mae: 0.4999\n",
            "Epoch 92/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.8884 - mae: 0.8884\n",
            "Epoch 93/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.4579 - mae: 0.4579\n",
            "Epoch 94/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.8480 - mae: 0.8480\n",
            "Epoch 95/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 1.0525 - mae: 1.0525\n",
            "Epoch 96/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6300 - mae: 0.6300\n",
            "Epoch 97/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.5738 - mae: 0.5738\n",
            "Epoch 98/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6951 - mae: 0.6951\n",
            "Epoch 99/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.1694 - mae: 0.1694\n",
            "Epoch 100/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.6228 - mae: 0.6228\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f8b602facd0>"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Let's rebuild model\n",
        "\n",
        "# 1. Create a model \n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(100, activation='relu'),\n",
        "    tf.keras.layers.Dense(100, activation='relu'),\n",
        "    tf.keras.layers.Dense(100, activation='relu'),\n",
        "    tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "# 2. Compiling model\n",
        "model.compile(\n",
        "    loss=tf.keras.losses.mae,\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.01),\n",
        "    metrics=['mae']\n",
        ")\n",
        "\n",
        "# 3. Fit the model\n",
        "model.fit(tf.expand_dims(X, axis=-1), y, epochs=100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "OY2ducXx6SPc",
        "outputId": "15680ca2-8db1-44fb-f025-484e998dfc77"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(8,), dtype=float64, numpy=array([-7., -4., -1.,  2.,  5.,  8., 11., 14.])>,\n",
              " <tf.Tensor: shape=(8,), dtype=float64, numpy=array([ 3.,  6.,  9., 12., 15., 18., 21., 24.])>)"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Remind the data\n",
        "X, y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "BoczlBnp6SMu",
        "outputId": "82cb209f-c476-42ee-f0b5-2098668ec3dc"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f8b60370d30> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 75ms/step\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "array([[26.732338]], dtype=float32)"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Make a prediction\n",
        "model.predict([17.0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bscu82sZ6R7k"
      },
      "source": [
        "Woowww.. It's look the best prediction.."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bwsdnptQ2iFC"
      },
      "source": [
        "### Common ways to improve a deep model\n",
        "\n",
        "* Adding more hidden layers\n",
        "* Adding more neurons\n",
        "* Change the activation function\n",
        "* Change the optimization function\n",
        "* Change the learning rate\n",
        "* Fitting for longer (increase number of epoch)\n",
        "* Fitting on more data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_SPSH0Nc4rqr"
      },
      "source": [
        "## Evaluating a model\n",
        "\n",
        "In practice, a typical workflow  you'll go through when building neural networks is:\n",
        "\n",
        "```\n",
        "Build a model -> Fit it -> Evaluate it -> Tweak a model -> Fit it -> Evaluate it -> Tweak a model -> Fit it -> Evaluate it -> Tweak a model -> Fit it -> Evaluate it ```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JGDJcr2P8A5R"
      },
      "source": [
        "When it comes to evaluation. There are 3 words you memorized:\n",
        "\n",
        "> 'Visualize, Visualize, Visualize...'\n",
        "\n",
        "It is a good idea to visualize:\n",
        "* The data - What data are we working with? What does it look like?\n",
        "* The model itself - What does model look like?\n",
        "* Traning of a model - How does a model perform while it learns?\n",
        "* Prediction of the model -  How do the predictions of a model line up aganist the truth?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "P2nA42oGlEgv",
        "outputId": "8fc14597-2e86-4f12-a9d4-202eabe3eb4c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(50,), dtype=int32, numpy=\n",
              "array([-100,  -96,  -92,  -88,  -84,  -80,  -76,  -72,  -68,  -64,  -60,\n",
              "        -56,  -52,  -48,  -44,  -40,  -36,  -32,  -28,  -24,  -20,  -16,\n",
              "        -12,   -8,   -4,    0,    4,    8,   12,   16,   20,   24,   28,\n",
              "         32,   36,   40,   44,   48,   52,   56,   60,   64,   68,   72,\n",
              "         76,   80,   84,   88,   92,   96], dtype=int32)>"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Make a bigger dataset\n",
        "X = tf.range(-100, 100, 4)\n",
        "X"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "IgWEHAe7lG3C",
        "outputId": "4ff06379-96a4-4698-c2f5-6fb494c58617"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(50,), dtype=int32, numpy=\n",
              "array([-90, -86, -82, -78, -74, -70, -66, -62, -58, -54, -50, -46, -42,\n",
              "       -38, -34, -30, -26, -22, -18, -14, -10,  -6,  -2,   2,   6,  10,\n",
              "        14,  18,  22,  26,  30,  34,  38,  42,  46,  50,  54,  58,  62,\n",
              "        66,  70,  74,  78,  82,  86,  90,  94,  98, 102, 106], dtype=int32)>"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# make labels for dataset\n",
        "y = X + 10\n",
        "y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "id": "O33QBoDPmIC3",
        "outputId": "8acce8b4-cf8f-42aa-b0f5-91f3aee29512"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Plot data\n",
        "plt.scatter(X, y)\n",
        "plt.xlabel('X')\n",
        "plt.ylabel('y')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uDbreGfPmWUP"
      },
      "source": [
        "### The three sets\n",
        "\n",
        "* **Train set** - The model learns from this data, which is typically 70-80% of total data\n",
        "* **Validation set** - The model gets tuned on this data which is typically 10-15% of total data\n",
        "* **Test set** - The model gets evaulated on this data to test what is has learned, which is typically 10-15% of total data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "HdLMPbdeurWr",
        "outputId": "9a20f47f-97f9-4e7e-fec8-04df2ac3f1ea"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "50"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Check the lenth of how many data we have\n",
        "len(X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "KPe_rfukw3BO",
        "outputId": "da0eaf9c-c96f-4bac-e77a-eb08c2f3372b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(40, 10)"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Split the data into train and test set\n",
        "X_train = X[:40] # first 40 are train samples (80% of our data)\n",
        "y_train = y[:40]\n",
        "            \n",
        "X_test = X[40:] # last 10 are test samples (20% of our data)\n",
        "y_test = y[40:]\n",
        "\n",
        "len(X_train), len(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M7yCs5iVyP43"
      },
      "source": [
        "### Visualizing data \n",
        "\n",
        "Now we've got our data in train and test sets. Let's visualize it again."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "id": "6zKkqtH5zH3v",
        "outputId": "5c2610f2-e916-4acc-d167-76562067f3f6"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# plot training data in blue\n",
        "plt.scatter(X_train, y_train, c='b', label='train-set')\n",
        "# plot test data in red\n",
        "plt.scatter(X_test, y_test, c='r', label='test-set')\n",
        "# show legend\n",
        "plt.legend()\n",
        "plt.xlabel('X')\n",
        "plt.ylabel('y')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "6PIqmS7BzY1t"
      },
      "outputs": [],
      "source": [
        "# Let's build a neural network for our data\n",
        "\n",
        "# 1.Create a model\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "# 2.Compiling model\n",
        "model.compile(\n",
        "    loss=tf.keras.losses.mae,\n",
        "    optimizer=tf.keras.optimizers.SGD(),\n",
        "    metrics=['mae']\n",
        ")\n",
        "\n",
        "# 3.Fit the model\n",
        "# model.fit(tf.expand_dims(X, axis=-1), y, epochs=100) # Pass this part and check what will happen if we summary the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vS0c9GOzAbPF"
      },
      "source": [
        "### Visulazing the model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 287
        },
        "id": "6zyT7yn5AVit",
        "outputId": "86525f96-11e5-467c-d7e8-578a339f2e16"
      },
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-30-5f15418b3570>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36msummary\u001b[0;34m(self, line_length, positions, print_fn, expand_nested, show_trainable, layer_range)\u001b[0m\n\u001b[1;32m   3227\u001b[0m         \"\"\"\n\u001b[1;32m   3228\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3229\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m   3230\u001b[0m                 \u001b[0;34m\"This model has not yet been built. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3231\u001b[0m                 \u001b[0;34m\"Build the model first by calling `build()` or by calling \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: This model has not yet been built. Build the model first by calling `build()` or by calling the model on a batch of data."
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "SsPjpAsYAj9d"
      },
      "outputs": [],
      "source": [
        "# Let's create a model which builds automatically by defining the input_shape argument\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# 1. Create a model (same as above we just add input_shape in Dense)\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(15, input_shape=[1], name='input_layer'),\n",
        "    tf.keras.layers.Dense(1, name='output_layer')\n",
        "], name='model_1')\n",
        "\n",
        "# 2. Compiling model\n",
        "model.compile(\n",
        "    loss=tf.keras.losses.mae,\n",
        "    optimizer=tf.keras.optimizers.SGD(),\n",
        "    metrics=['mae']\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "W5oh5OXxDTAT"
      },
      "outputs": [],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gO2Hw6UnDqMK"
      },
      "source": [
        "Woww. Its work, now. But, what does it mean?\n",
        "\n",
        "* **Total params** - Total number of parameters in the model\n",
        "* **Trainable params** - These are the parameters that model can update as it trains.\n",
        "* **Non-traianble params** - These are the parameters that model can not update (this is typical when you bring in already learn parameters from other models during transfer learning)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "1FXHOOZeH-_w"
      },
      "outputs": [],
      "source": [
        "# Fit the model with training data\n",
        "model.fit(tf.expand_dims(X_train, axis=-1), y_train, epochs=100, verbose=0) # verbose=0 means that dont show the progress bar as output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "rwG_wSE3RWLG"
      },
      "outputs": [],
      "source": [
        "# Get the summary of the model\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "7-CFunf0NGrA"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.utils import plot_model\n",
        "\n",
        "plot_model(model=model, show_shapes=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m5tFEImVOhZh"
      },
      "source": [
        "### Visulazing our model's predictions\n",
        "\n",
        "To visualize the predictions, it is good idea to plot them against the truth labels.\n",
        "\n",
        "We generally call this as `y_preds`, `y_test` and `y_true`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "6dmUAyDAQ-2B"
      },
      "outputs": [],
      "source": [
        "# Make some predictions\n",
        "y_pred = model.predict(X_test)\n",
        "y_pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "mUaiAu1kSbsF"
      },
      "outputs": [],
      "source": [
        "# Let's create a plotting function\n",
        "def plot_prediction(train_data=X_train, train_labels=y_train, \n",
        "     test_data=X_test, test_labels=y_test, predictions=y_pred):\n",
        "  \n",
        "  '''Ploting train data, test data and compare predictions with actual values'''\n",
        "\n",
        "  # Plot training data in blue\n",
        "  plt.scatter(train_data, train_labels, c='b', label='Training data')\n",
        "  # Plot test data in green\n",
        "  plt.scatter(test_data, test_labels, c='g', label='Test data')\n",
        "  # Plot model in red\n",
        "  plt.scatter(test_data, predictions, c='r', label='Prediction')\n",
        "  # Show legend and plot\n",
        "  plt.legend()\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "HTyT20V0StaZ"
      },
      "outputs": [],
      "source": [
        "plot_prediction(train_data=X_train,\n",
        "                train_labels=y_train,\n",
        "                test_data=X_test,\n",
        "                test_labels=y_test,\n",
        "                predictions=y_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "plsHq7VJV6FC"
      },
      "source": [
        "### Evaluating our model's predictions with regression evaluation metrics\n",
        "\n",
        "Depending problem you are working on, there will be different evaluation metrics to evaluate your model's performance.\n",
        "\n",
        "There are two main metrics for regression problem:\n",
        "* MAE - mean absolute error, on average, how wrong is each of model's predictions\n",
        "* MSE - mean square error, 'square the average errors'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "QwdPED17XEGR"
      },
      "outputs": [],
      "source": [
        "  # Evaluate the model on the test set\n",
        "  model.evaluate(X_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "ZSjtT6U1XFi8"
      },
      "outputs": [],
      "source": [
        "# Calculate the mean absolute error\n",
        "mae = tf.keras.losses.mean_absolute_error(y_true=y_test, \n",
        "                                    y_pred=tf.squeeze(y_pred)) # we used tf.squeeze for y_pred becase shape of y_pred is not same with y_test\n",
        "mae"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "6O7sljtjrKr4"
      },
      "outputs": [],
      "source": [
        "# Calculate the mean square error\n",
        "mse = tf.keras.losses.mean_squared_error(y_true=y_test, \n",
        "                                    y_pred=tf.squeeze(y_pred))\n",
        "mse"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "CpjbyUaZr-gg"
      },
      "outputs": [],
      "source": [
        "# Make some functions to reuse MAE and MSE\n",
        "def mae(y_true, y_pred):\n",
        "  return tf.keras.losses.mean_absolute_error(y_true, tf.squeeze(y_pred)).numpy()\n",
        "\n",
        "def mse(y_true, y_pred):\n",
        "  return tf.keras.losses.mean_squared_error(y_true, tf.squeeze(y_pred)).numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "AFz_O7B0ufog"
      },
      "outputs": [],
      "source": [
        "# MAE and MSE\n",
        "print(f'Mean Absolute Error (MAE): {mae(y_test, y_pred)}')\n",
        "print(f'Mean Square Error (MSE): {mse(y_test, y_pred)}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qfI6iHOgumRI"
      },
      "source": [
        "### Running experiments to improve model\n",
        "\n",
        "\n",
        "Build a model -> Fit it -> Evaluate it -> Tweak it -> Fit it -> Evaluate it -> tweak it -> Evaluate it\n",
        "\n",
        "\n",
        "1. Get more data - get more examples for your model to train on.\n",
        "2. Make your model larger (using more complex model) - this might come in the form more layers on more neoron\n",
        "3. Train for longer - give your model more of a chance to find patterns in the data\n",
        "\n",
        "Let's do 3 modelling experiments:\n",
        "\n",
        "1. `model_1` - same as the original model, 1 layer, trained for 100 eepochs\n",
        "2. `model_2` - 2 layers, trained for 100 epochs\n",
        "3. `model_3` - 2 layers, trained for 500 epochs\n",
        "\n",
        "**Build `model_1`**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "iZqzUBMeu07Y"
      },
      "outputs": [],
      "source": [
        "# set random seed\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# 1. Create the model\n",
        "model_1 = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "# 2. Compile the model\n",
        "model_1.compile(\n",
        "     loss=tf.keras.losses.mae,\n",
        "     optimizer=tf.keras.optimizers.SGD(),\n",
        "     metrics=['mae']\n",
        ")\n",
        "\n",
        "# 3. Fit the model\n",
        "model_1.fit(tf.expand_dims(X_train, axis=-1), y_train, epochs=100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "S8LEnanay0q_"
      },
      "outputs": [],
      "source": [
        "# Make and plot prediction for model_1\n",
        "y_pred_1 = model_1.predict(X_test)\n",
        "plot_prediction(train_data=X_train,\n",
        "                train_labels=y_train,\n",
        "                test_data=X_test,\n",
        "                test_labels=y_test,\n",
        "                predictions=y_pred_1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "bxez890PzoR4"
      },
      "outputs": [],
      "source": [
        "# Calculate evaluation metrics for model_!\n",
        "print('Mean Absolute Error (MAE):', mae(y_test, y_pred_1))\n",
        "print('Mean Square Error (MSE):', mse(y_test, y_pred_1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CuA5n2uh0gXY"
      },
      "source": [
        "**Build `model_2`**\n",
        "\n",
        "* 2 layers, trained for 100 epochs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Q9r6xJ-42Bwf"
      },
      "outputs": [],
      "source": [
        "# Set random seed\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# 1. Create the model\n",
        "model_2 = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(10),\n",
        "    tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "# 2. Compile the model\n",
        "model_2.compile(\n",
        "     loss=tf.keras.losses.mae,\n",
        "     optimizer=tf.keras.optimizers.SGD(),\n",
        "     metrics=['mae']\n",
        ")\n",
        "\n",
        "# 3. Fit the model\n",
        "model_2.fit(tf.expand_dims(X_train, axis=-1), y_train, epochs=100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "xQaEsmok2aqf"
      },
      "outputs": [],
      "source": [
        "# Make and plot predictions\n",
        "y_pred_2 = model_2.predict(X_test)\n",
        "plot_prediction(predictions=y_pred_2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "MVnY6_3J2lQw"
      },
      "outputs": [],
      "source": [
        "# Calculate evaluation metrics for model_2\n",
        "print('Mean Absolute Error (MAE):', mae(y_test, y_pred_2))\n",
        "print('Mean Square Error (MSE):', mse(y_test, y_pred_2))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TS9rpAT623hP"
      },
      "source": [
        "**Build `model_3`**\n",
        "\n",
        "* 2 layers, trained for 500 epochs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "DxX_zGoO4OOg"
      },
      "outputs": [],
      "source": [
        "# Set random seed\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# 1. Create the model\n",
        "model_3 = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(10),\n",
        "    tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "# 2. Compile the model\n",
        "model_3.compile(\n",
        "     loss=tf.keras.losses.mae,\n",
        "     optimizer=tf.keras.optimizers.SGD(),\n",
        "     metrics=['mae']\n",
        ")\n",
        "\n",
        "# 3. Fit the model\n",
        "model_3.fit(tf.expand_dims(X_train, axis=-1), y_train, epochs=500, verbose=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "g_uKIl7G4UsH"
      },
      "outputs": [],
      "source": [
        "# Make and plot predictions\n",
        "y_pred_3 = model_3.predict(X_test)\n",
        "plot_prediction(predictions=y_pred_3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "elemI1h-5knv"
      },
      "outputs": [],
      "source": [
        "# Calculate evaluation metrics for model_3\n",
        "print('Mean Absolute Error (MAE):', mae(y_test, y_pred_3))\n",
        "print('Mean Square Error (MSE):', mse(y_test, y_pred_3))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sgFljk1Y4jMP"
      },
      "source": [
        "We get very poor predictions for model_3 because we trained to much our model and model overfit."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ceQnWiVv50HP"
      },
      "source": [
        "## Comparing the results of our experiments\n",
        "\n",
        "We've run a few experiments, let's compare the results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "KvcYWtUI6TJY"
      },
      "outputs": [],
      "source": [
        "# Let's compare our model's results using pandas DataFrame\n",
        "import pandas as pd\n",
        "\n",
        "# model results\n",
        "model_results = [['model_1', mae(y_test, y_pred_1), mse(y_test, y_pred_1)], \n",
        "                 ['model_2', mae(y_test, y_pred_2), mse(y_test, y_pred_2)], \n",
        "                 ['model_3', mae(y_test, y_pred_3), mse(y_test, y_pred_3)]]\n",
        "\n",
        "# Create a dataframe and add results in it\n",
        "results_df = pd.DataFrame(model_results, columns=['models', 'MAE', 'MSE'])\n",
        "results_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mu4hGuB19O0k"
      },
      "source": [
        "Looks like model_2 performed the best."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "LOiLcidk7t9Y"
      },
      "outputs": [],
      "source": [
        " # model summaray\n",
        " model_2.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Aohxegp78-1H"
      },
      "source": [
        "Note: One of our main goals should be to minimize the time between our experiments. The more experiments we do, the more things we will figure out which doenst work and in turni get closer to figureing out what does work. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "etXclvyp-QTp"
      },
      "source": [
        "## Tracking your experiments\n",
        "\n",
        "One really good habit in machine learning modelling is to track the results of your experiments.\n",
        "\n",
        "And when doing so, it can be tedious if you are running lots of experiments. \n",
        "\n",
        "Luckly, there are tools to help us.\n",
        "\n",
        "* TensorBoard - a component of the tensorflow library to help track modelling experiments.\n",
        "* Wights & Biases - a tool for tracking all of kinds of machine learning experiments\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d-M-sY_i-cAn"
      },
      "source": [
        "## Saving our models\n",
        "\n",
        "Saving model allows us to use models out of Colab such as web application or mobile app etc.\n",
        "\n",
        "There are two main formats we can save our model's:\n",
        "1. The SavedModel format\n",
        "2. The HDF5 format"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "XczmN8H1_uua"
      },
      "outputs": [],
      "source": [
        "# Save model using the SavedModel format\n",
        "model_2.save('SavedModel_format') "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "3Rh69i0jESW7"
      },
      "outputs": [],
      "source": [
        "# Save model using the HDF5 format\n",
        "model_2.save('HDF5_format.h5')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P_eYiwYeFheV"
      },
      "source": [
        "## Loading in saved model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "AuT8e6teFxJv"
      },
      "outputs": [],
      "source": [
        "# Load in the SavedModel format model\n",
        "loaded_SavedModel_format = tf.keras.models.load_model('/content/SavedModel_format')\n",
        "loaded_SavedModel_format.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "QUOiuZqNGhL3"
      },
      "outputs": [],
      "source": [
        "# Compare model_2 predictions with SavedModel predictions\n",
        "print('Model_2 predictions:', model_2.predict(X_test), '\\n')\n",
        "print('SavedModel predictions:', loaded_SavedModel_format.predict(X_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "q7-gkCyfG_pu"
      },
      "outputs": [],
      "source": [
        "# Load in the .h5 format model\n",
        "loaded_h5_model = tf.keras.models.load_model('/content/HDF5_format.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "6wvIF1YYIxTB"
      },
      "outputs": [],
      "source": [
        "# Compare model_2 predictions with loaded_h5_model predictions\n",
        "print('Model_2 predictions:', model_2.predict(X_test), '\\n')\n",
        "print('HDF5 predictions:', loaded_h5_model.predict(X_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nu2_mOwmNrCu"
      },
      "source": [
        "## A Larger Example - Medical Cost Personal Datasets\n",
        "\n",
        "* Resource: https://www.kaggle.com/datasets/mirichoi0218/insurance\n",
        "* Raw csv file: https://raw.githubusercontent.com/stedy/Machine-Learning-with-R-datasets/master/insurance.csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "CCVyelNLOhLf"
      },
      "outputs": [],
      "source": [
        "# Import required libraries\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Read insurance dataset\n",
        "df = pd.read_csv('https://raw.githubusercontent.com/stedy/Machine-Learning-with-R-datasets/master/insurance.csv')\n",
        "\n",
        "# Let's look first five rows\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "1CVeCN8hQV3t"
      },
      "outputs": [],
      "source": [
        "# Dataframe info \n",
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "0rSW1NCsSAFO"
      },
      "outputs": [],
      "source": [
        "# Let's try one-hot encode our data\n",
        "df_one_hot = pd.get_dummies(df, prefix=['sex', 'smoker', 'region'], drop_first=True)\n",
        "df_one_hot.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "2dE_9RB0Ssct"
      },
      "outputs": [],
      "source": [
        " # Create X & y values (features and labels)\n",
        " X = df_one_hot.drop('charges', axis=1)\n",
        " y = df_one_hot['charges']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "niXBL2hxVlhO"
      },
      "outputs": [],
      "source": [
        "# View X\n",
        "X.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "2NxrExUhVlem"
      },
      "outputs": [],
      "source": [
        "# View y\n",
        "y.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "5ovO_xNZU0FO"
      },
      "outputs": [],
      "source": [
        " # Create training and test sets\n",
        " X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        " print('Total data size:', len(X))\n",
        " print('Train data size:', len(X_train))\n",
        " print('Test data size:', len(X_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "f-lCOykBUxIF"
      },
      "outputs": [],
      "source": [
        " # Build a neural network\n",
        "\n",
        " # Set random seed\n",
        " tf.random.set_seed(42)\n",
        "\n",
        " # 1. Create a model\n",
        " model = tf.keras.Sequential([\n",
        "     tf.keras.layers.Dense(1),\n",
        "     tf.keras.layers.Dense(1)\n",
        " ])\n",
        "\n",
        " # 2. Model compiling\n",
        " model.compile(\n",
        "     loss=tf.keras.losses.mae,\n",
        "     optimizer=tf.keras.optimizers.SGD(),\n",
        "     metrics = ['mae']\n",
        " )\n",
        "\n",
        " # 3. Fit the model\n",
        " model.fit(X_train, y_train, epochs=100, verbose=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "XbJxU0y0Y_hV"
      },
      "outputs": [],
      "source": [
        "# Check the results of the model on the test data\n",
        "model.evaluate(X_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "sZRDpKdMbkWW"
      },
      "outputs": [],
      "source": [
        "# Let's check the mean and median of test data\n",
        "y_test.median(), y_test.mean()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WU92nROZbawy"
      },
      "source": [
        "If we check the mean and median of the y value we can see that our predictions are so poor. Let's try to improve our model.\n",
        "\n",
        "To try improve our model, we'll run 2 experiments:\n",
        "1. Add an extra layer with mode hidden units\n",
        "2. Train for longer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "FWkJLJnBcCHZ"
      },
      "outputs": [],
      "source": [
        "# Set random seed\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# 1. Create the model\n",
        "insurance_model_1 =  tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(100),\n",
        "    tf.keras.layers.Dense(10),\n",
        "    tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "# 2. Compile the model\n",
        "insurance_model_1.compile(\n",
        "    loss=tf.keras.losses.mae,\n",
        "    optimizer=tf.keras.optimizers.Adam(),\n",
        "    metrics=['mae']\n",
        ")\n",
        "\n",
        "# 3. Fit the model\n",
        "history_1 = insurance_model_1.fit(X_train, y_train, epochs=100, verbose=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "-RnI2HdiOnly"
      },
      "outputs": [],
      "source": [
        "# plot the training loss and validation loss\n",
        "plt.plot(history_1.history['loss'])\n",
        "plt.title('Model Loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "A4lkwNUSJm2B"
      },
      "outputs": [],
      "source": [
        "# Evaluate insurance_model_1\n",
        "insurance_model_1.evaluate(X_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Qu41dmm5KQbw"
      },
      "outputs": [],
      "source": [
        "# Same as above only we decrease the epochs\n",
        "\n",
        "# Set random seed\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# 1. Create the model\n",
        "insurance_model_2 =  tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(100),\n",
        "    tf.keras.layers.Dense(10),\n",
        "    tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "# 2. Compile the model\n",
        "insurance_model_2.compile(\n",
        "    loss=tf.keras.losses.mae,\n",
        "    optimizer=tf.keras.optimizers.Adam(),\n",
        "    metrics=['mae']\n",
        ")\n",
        "\n",
        "# 3. Fit the model\n",
        "history_2 = insurance_model_2.fit(X_train, y_train, epochs=200, verbose=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "INjVQK5RQwYY"
      },
      "outputs": [],
      "source": [
        "# plot the training loss and validation loss\n",
        "plt.plot(history_2.history['loss'])\n",
        "plt.title('Model Loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "QXnBMKynMkx5"
      },
      "outputs": [],
      "source": [
        "# Evaluate insurance_model_2\n",
        "insurance_model_2.evaluate(X_test, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sPHlNtFsOIwI"
      },
      "source": [
        "As you see above, we improved our model but now, we should think that how long we train our model. It depends on the problem we are working on. There in no exact solution. But TensorFlow has a solution and it is called the [EarlyStopping Callback](https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/EarlyStopping)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HkM_nT6FUMt2"
      },
      "source": [
        "## Preprocessing data (normalization and standardization)\n",
        "\n",
        "What is normalization? \n",
        "\n",
        "The answer: [Normalization and Standardization](https://scikit-learn.org/stable/modules/preprocessing.html)\n",
        "\n",
        "In terms of scaling values, neural networks tend to prefer normalization. If you are not sure on which one use, try both and see which performs better."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EIFf40wXj04A"
      },
      "source": [
        "Let's reimport our data and make preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "bBvZ-X5Pjms5"
      },
      "outputs": [],
      "source": [
        "# Read insurance dataset\n",
        "df = pd.read_csv('https://raw.githubusercontent.com/stedy/Machine-Learning-with-R-datasets/master/insurance.csv')\n",
        "\n",
        "# firs five row\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "PQv9iZfMhRwr"
      },
      "outputs": [],
      "source": [
        "# import neccessary classes from sklearn\n",
        "from sklearn.compose import make_column_transformer\n",
        "from sklearn.preprocessing import MinMaxScaler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "dh1MBBETV_6l"
      },
      "outputs": [],
      "source": [
        "# Create a column transformer\n",
        "ct = make_column_transformer(\n",
        "    (MinMaxScaler(), ['age', 'bmi', 'children']), # turn all values in between 0 and 1 \n",
        "    (OneHotEncoder(handle_unknown='ignore', drop='first'), ['sex', 'smoker', 'region'])\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "sEo-2P8FhPaf"
      },
      "outputs": [],
      "source": [
        "# Create X and y (features and labes)\n",
        "X = df.drop('charges', axis=1)\n",
        "y = df['charges']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "2lRobiDpkki_"
      },
      "outputs": [],
      "source": [
        "# Split data to train and test\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "agO5f6C4pyic"
      },
      "outputs": [],
      "source": [
        "# Fit the column transform to our training data\n",
        "ct.fit(X_train)\n",
        "\n",
        "# Transform training and test data with normalization (MinMaxScaler) and OneHotEncoder\n",
        "X_train_normal = ct.transform(X_train)\n",
        "X_test_normal = ct.transform(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "hEiZ89CWsIw6"
      },
      "outputs": [],
      "source": [
        "# Check the data what look like\n",
        "X_train_normal[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GUyL6mFAsqGh"
      },
      "source": [
        "Now, our data has been normalized and one hot encoded. Let's build a neural network model with our nomalized data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "-abW2JFXtTBP"
      },
      "outputs": [],
      "source": [
        "# Set random seed\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# 1. Create the model\n",
        "insurance_model_3 =  tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(100),\n",
        "    tf.keras.layers.Dense(10),\n",
        "    tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "# 2. Compile the model\n",
        "insurance_model_3.compile(\n",
        "    loss=tf.keras.losses.mae,\n",
        "    optimizer=tf.keras.optimizers.Adam(),\n",
        "    metrics=['mae']\n",
        ")\n",
        "\n",
        "# 3. Fit the model\n",
        "history_3 = insurance_model_3.fit(X_train_normal, y_train, epochs=200, verbose=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "A3nz1lusuc3Z"
      },
      "outputs": [],
      "source": [
        "# plot the training loss and validation loss\n",
        "plt.plot(history_3.history['loss'])\n",
        "plt.title('Model Loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "RZHoo00Augop"
      },
      "outputs": [],
      "source": [
        "# Model evaluation\n",
        "insurance_model_3.evaluate(X_test_normal, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n1asHwEtvH3Y"
      },
      "source": [
        "Insurance model 2 resulst:\n",
        "* 9/9 [==============================] - 0s 2ms/step - loss: 3440.0859 - mae: 3440.0859\n",
        "\n",
        "Result after normalization:\n",
        "* 9/9 [==============================] - 0s 2ms/step - loss: 3244.9829 - mae: 3244.9829"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "toc_visible": true,
      "provenance": [],
      "authorship_tag": "ABX9TyNrDoCHQCKTgYWBL9HxJuIH"
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}